{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "musical-stand",
   "metadata": {},
   "source": [
    "# Cleaning of Benchmark Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "sitting-madness",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import relevant libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cognitive-frame",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "annual-hopkins",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the generated csv-files from webscraping\n",
    "df_bs_01 = pd.read_csv('./data/2019_opens_bs_01.csv')\n",
    "df_bs_02 = pd.read_csv('./data/2019_opens_bs_02.csv')\n",
    "df_bs_03 = pd.read_csv('./data/2019_opens_bs_03.csv')\n",
    "df_bs_04 = pd.read_csv('./data/2019_opens_bs_04.csv')\n",
    "df_bs_05 = pd.read_csv('./data/2019_opens_bs_05.csv')\n",
    "df_bs_06 = pd.read_csv('./data/2019_opens_bs_06.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "pretty-monthly",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the datasets to one dataframe and sort by competitor ids\n",
    "df_bs = pd.concat([df_bs_01, df_bs_02, df_bs_03, df_bs_04, df_bs_05, df_bs_06])\n",
    "df_bs = df_bs.drop_duplicates(subset=\"competitorid\")\n",
    "df_bs = df_bs.sort_values(by='competitorid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "molecular-attempt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns which are already considered in core dataframe\n",
    "df_bs = df_bs.drop(columns=['fullname','countryoforigin','division','affiliate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "damaged-editing",
   "metadata": {},
   "source": [
    "### Creating Clean Lists of Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "rough-refund",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create clean list of bs_backsquat\n",
    "# set bs_backsquat between 20 and 250 kg\n",
    "backsquat_list = df_bs['bs_backsquat'].to_list()\n",
    "new_backsquat_list = []\n",
    "for weight in backsquat_list:\n",
    "    if 'lb' in weight:\n",
    "        weight_kg = int(float(weight.strip('lb'))*0.453592)\n",
    "        if weight_kg > 19 and weight_kg < 251:\n",
    "            new_backsquat_list.append(weight_kg)\n",
    "        else:\n",
    "            new_backsquat_list.append(np.NaN)\n",
    "    elif 'kg' in weight:\n",
    "        weight_kg = int(float(weight.strip('kg')))\n",
    "        if weight_kg > 19 and weight_kg < 251:\n",
    "            new_backsquat_list.append(weight_kg)\n",
    "        else:\n",
    "            new_backsquat_list.append(np.NaN)\n",
    "    elif weight == '--':\n",
    "        new_backsquat_list.append(np.NaN)\n",
    "    else:\n",
    "        new_backsquat_list.append(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "secret-timeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create clean list of bs_cleanandjerk\n",
    "# set bs_cleanandjerk between 20 and 200 kg\n",
    "cleanandjerk_list = df_bs['bs_cleanandjerk'].to_list()\n",
    "new_cleanandjerk_list = []\n",
    "for weight in cleanandjerk_list:\n",
    "    if 'lb' in weight:\n",
    "        weight_kg = int(float(weight.strip('lb'))*0.453592)\n",
    "        if weight_kg > 19 and weight_kg < 201:\n",
    "            new_cleanandjerk_list.append(weight_kg)\n",
    "        else:\n",
    "            new_cleanandjerk_list.append(np.NaN)\n",
    "    elif 'kg' in weight:\n",
    "        weight_kg = int(float(weight.strip('kg')))\n",
    "        if weight_kg > 19 and weight_kg < 201:\n",
    "            new_cleanandjerk_list.append(weight_kg)\n",
    "        else:\n",
    "            new_cleanandjerk_list.append(np.NaN)\n",
    "    elif weight == '--':\n",
    "        new_cleanandjerk_list.append(np.NaN)\n",
    "    else:\n",
    "        new_cleanandjerk_list.append(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "detected-following",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create clean list of bs_snatch\n",
    "# set bs_snatch between 20 and 160 kg\n",
    "snatch_list = df_bs['bs_snatch'].to_list()\n",
    "new_snatch_list = []\n",
    "for weight in snatch_list:\n",
    "    if 'lb' in weight:\n",
    "        weight_kg = int(float(weight.strip('lb'))*0.453592)\n",
    "        if weight_kg > 19 and weight_kg < 161:\n",
    "            new_snatch_list.append(weight_kg)\n",
    "        else:\n",
    "            new_snatch_list.append(np.NaN)\n",
    "    elif 'kg' in weight:\n",
    "        weight_kg = int(float(weight.strip('kg')))\n",
    "        if weight_kg > 19 and weight_kg < 161:\n",
    "            new_snatch_list.append(weight_kg)\n",
    "        else:\n",
    "            new_snatch_list.append(np.NaN)\n",
    "    elif weight == '--':\n",
    "        new_snatch_list.append(np.NaN)\n",
    "    else:\n",
    "        new_snatch_list.append(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "human-tension",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create clean list of bs_deadlift\n",
    "# set bs_deadlift between 20 and 300 kg\n",
    "deadlift_list = df_bs['bs_deadlift'].to_list()\n",
    "new_deadlift_list = []\n",
    "for weight in deadlift_list:\n",
    "    if 'lb' in weight:\n",
    "        weight_kg = int(float(weight.strip('lb'))*0.453592)\n",
    "        if weight_kg > 19 and weight_kg < 301:\n",
    "            new_deadlift_list.append(weight_kg)\n",
    "        else:\n",
    "            new_deadlift_list.append(np.NaN)\n",
    "    elif 'kg' in weight:\n",
    "        weight_kg = int(float(weight.strip('kg')))\n",
    "        if weight_kg > 19 and weight_kg < 301:\n",
    "            new_deadlift_list.append(weight_kg)\n",
    "        else:\n",
    "            new_deadlift_list.append(np.NaN)\n",
    "    elif weight == '--':\n",
    "        new_deadlift_list.append(np.NaN)\n",
    "    else:\n",
    "        new_deadlift_list.append(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "lesser-reward",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create clean list of bs_fightgonebad\n",
    "# set bs_fightgonebad between 150 and 600 reps\n",
    "fightgonebad_list = df_bs['bs_fightgonebad'].to_list()\n",
    "new_fightgonebad_list = []\n",
    "for reps in fightgonebad_list:\n",
    "    if reps == '--':\n",
    "        new_fightgonebad_list.append(np.NaN)\n",
    "    else:\n",
    "        if int(reps) >= 150 and int(reps) <= 600:\n",
    "            new_fightgonebad_list.append(int(reps))\n",
    "        else:\n",
    "            new_fightgonebad_list.append(np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "southern-belgium",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create clean list of bs_maxpull_ups\n",
    "# set bs_maxpull_ups between 0 and 1000 reps\n",
    "maxpull_ups_list = df_bs['bs_maxpull_ups'].to_list()\n",
    "new_maxpull_ups_list = []\n",
    "for reps in maxpull_ups_list:\n",
    "    if reps == '--':\n",
    "        new_maxpull_ups_list.append(np.NaN)\n",
    "    else:\n",
    "        if int(reps) >= 0 and int(reps) < 1000:\n",
    "            new_maxpull_ups_list.append(int(reps))\n",
    "        else:\n",
    "            new_maxpull_ups_list.append(np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "based-source",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create clean list of bs_fran\n",
    "# set bs_fran between 100 and 2000 seconds\n",
    "fran_list = df_bs['bs_fran'].to_list()\n",
    "new_fran_list = []\n",
    "for t in fran_list:\n",
    "    if t == '--':\n",
    "        new_fran_list.append(np.NaN)\n",
    "    elif ':' in t:\n",
    "        segm = t.split(':')\n",
    "        f_time = int(segm[0])*60 + int(segm[1])\n",
    "        if f_time > 100 and f_time < 2000:\n",
    "            new_fran_list.append(f_time)\n",
    "        else:\n",
    "            new_fran_list.append(np.NaN)\n",
    "    else:\n",
    "        new_fran_list.append(int(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "engaging-booking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create clean list of bs_grace\n",
    "# set bs_grace between 50 and 2000 seconds\n",
    "grace_list = df_bs['bs_grace'].to_list()\n",
    "new_grace_list = []\n",
    "for t in grace_list:\n",
    "    if t == '--':\n",
    "        new_grace_list.append(np.NaN)\n",
    "    elif ':' in t:\n",
    "        segm = t.split(':')\n",
    "        g_time = int(segm[0])*60 + int(segm[1])\n",
    "        if g_time > 50 and g_time < 2000:\n",
    "            new_grace_list.append(g_time)\n",
    "        else:\n",
    "            new_grace_list.append(np.NaN)\n",
    "    else:\n",
    "        new_grace_list.append(int(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "functioning-stuff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create clean list of bs_helen\n",
    "# set bs_helen between 300 and 1500 seconds\n",
    "helen_list = df_bs['bs_helen'].to_list()\n",
    "new_helen_list = []\n",
    "for t in helen_list:\n",
    "    if t == '--':\n",
    "        new_helen_list.append(np.NaN)\n",
    "    elif ':' in t:\n",
    "        segm = t.split(':')\n",
    "        h_time = int(segm[0])*60 + int(segm[1])\n",
    "        if h_time > 300 and h_time < 1500:\n",
    "            new_helen_list.append(h_time)\n",
    "        else:\n",
    "            new_helen_list.append(np.NaN)\n",
    "    else:\n",
    "        new_helen_list.append(int(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "diverse-scheme",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create clean list of bs_filthy50\n",
    "# set bs_filthy50 between 500 and 4000 seconds\n",
    "filthy50_list = df_bs['bs_filthy50'].to_list()\n",
    "new_filthy50_list = []\n",
    "for t in filthy50_list:\n",
    "    if t == '--':\n",
    "        new_filthy50_list.append(np.NaN)\n",
    "    elif ':' in t:\n",
    "        segm = t.split(':')\n",
    "        f_time = int(segm[0])*60 + int(segm[1])\n",
    "        if f_time > 500 and f_time < 4000:\n",
    "            new_filthy50_list.append(f_time)\n",
    "        else:\n",
    "            new_filthy50_list.append(np.NaN)\n",
    "    else:\n",
    "        new_filthy50_list.append(int(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "opposite-technology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create clean list of bs_sprint400m\n",
    "# set bs_sprint400m between 50 and 200 seconds\n",
    "sprint400m_list = df_bs['bs_sprint400m'].to_list()\n",
    "new_sprint400m_list = []\n",
    "for t in sprint400m_list:\n",
    "    if t == '--':\n",
    "        new_sprint400m_list.append(np.NaN)\n",
    "    elif ':' in t:\n",
    "        segm = t.split(':')\n",
    "        s_time = int(segm[0])*60 + int(segm[1])\n",
    "        if s_time > 50 and s_time < 200:\n",
    "            new_sprint400m_list.append(s_time)\n",
    "        else:\n",
    "            new_sprint400m_list.append(np.NaN)\n",
    "    else:\n",
    "        new_sprint400m_list.append(int(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "characteristic-cooking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create clean list of bs_run5k\n",
    "# set bs_run5k between 500 and 5000 seconds\n",
    "run5k_list = df_bs['bs_run5k'].to_list()\n",
    "new_run5k_list = []\n",
    "for t in run5k_list:\n",
    "    if t == '--':\n",
    "        new_run5k_list.append(np.NaN)\n",
    "    elif ':' in t:\n",
    "        segm = t.split(':')\n",
    "        f_time = int(segm[0])*60 + int(segm[1])\n",
    "        if f_time > 500 and f_time < 5000:\n",
    "            new_run5k_list.append(f_time)\n",
    "        else:\n",
    "            new_run5k_list.append(np.NaN)\n",
    "    else:\n",
    "        new_run5k_list.append(int(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worthy-conjunction",
   "metadata": {},
   "source": [
    "### Add Clean Lists as Features to Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "systematic-young",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop original columns in dataframe\n",
    "orig_cols = [\n",
    "    'age', 'height', 'weight', \\\n",
    "    'bs_backsquat', 'bs_cleanandjerk', 'bs_snatch', 'bs_deadlift', \\\n",
    "    'bs_fightgonebad', 'bs_maxpull_ups', 'bs_fran', 'bs_grace', 'bs_helen', 'bs_filthy50', \\\n",
    "    'bs_sprint400m', 'bs_run5k'\n",
    "]\n",
    "df_bs = df_bs.drop(columns=orig_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "clean-steering",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add clean features to dataframe\n",
    "df_bs['bs_backsquat'] = new_backsquat_list\n",
    "df_bs['bs_cleanandjerk'] = new_cleanandjerk_list\n",
    "df_bs['bs_snatch'] = new_snatch_list\n",
    "df_bs['bs_deadlift'] = new_deadlift_list\n",
    "df_bs['bs_fightgonebad'] = new_fightgonebad_list\n",
    "df_bs['bs_maxpull_ups'] = new_maxpull_ups_list\n",
    "df_bs['bs_fran'] = new_fran_list\n",
    "df_bs['bs_grace'] = new_grace_list\n",
    "df_bs['bs_helen'] = new_helen_list\n",
    "df_bs['bs_filthy50'] = new_filthy50_list\n",
    "df_bs['bs_sprint400m'] = new_sprint400m_list\n",
    "df_bs['bs_run5k'] = new_run5k_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "italian-lucas",
   "metadata": {},
   "source": [
    "### Save Benchmark Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "falling-intranet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Benchmark Statistics of Athletes to csv-file\n",
    "df_bs.to_csv('./data/bs_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "physical-sociology",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
