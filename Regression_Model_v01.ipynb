{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "concrete-absolute",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressive-participant",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "through-ballet",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/2019_opens_clean.csv')\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "vocational-bedroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['competitorid','gender','age','height','weight','overallrank','is_scaled', \\\n",
    "        'scaled_1','scaled_2','scaled_3','scaled_4','scaled_5', \\\n",
    "        'time_2','time_3','time_4','time_5', \\\n",
    "        'bs_backsquat','bs_cleanandjerk','bs_snatch','bs_deadlift', 'bs_fightgonebad', \\\n",
    "        'bs_maxpull_ups', 'bs_fran','bs_grace','bs_helen', 'bs_filthy50','bs_sprint400m', \\\n",
    "        'bs_run5k','w1_reps_total','w2_reps_total','w2_reps_t2b','w2_reps_du','w2_reps_sqcl', \\\n",
    "        'w2_rounds_completed','w2_tiebreak', 'w3_reps_total','w3_hspu_status','w3_tiebreak', \\\n",
    "        'w4_reps_total','w4_reps_bmu','w4_bmu_status','w4_tiebreak','w5_reps_total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "numeric-testimony",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sufficient-zealand",
   "metadata": {},
   "source": [
    "### Quick look at data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "emotional-story",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 338538 entries, 0 to 338537\n",
      "Data columns (total 43 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   competitorid         338538 non-null  int64  \n",
      " 1   gender               338538 non-null  object \n",
      " 2   age                  338534 non-null  float64\n",
      " 3   height               180986 non-null  float64\n",
      " 4   weight               192160 non-null  float64\n",
      " 5   overallrank          338538 non-null  int64  \n",
      " 6   is_scaled            338538 non-null  int64  \n",
      " 7   scaled_1             338538 non-null  int64  \n",
      " 8   scaled_2             338538 non-null  int64  \n",
      " 9   scaled_3             338538 non-null  int64  \n",
      " 10  scaled_4             338538 non-null  int64  \n",
      " 11  scaled_5             338538 non-null  int64  \n",
      " 12  time_2               302615 non-null  float64\n",
      " 13  time_3               292251 non-null  float64\n",
      " 14  time_4               280276 non-null  float64\n",
      " 15  time_5               254423 non-null  float64\n",
      " 16  bs_backsquat         92107 non-null   float64\n",
      " 17  bs_cleanandjerk      84767 non-null   float64\n",
      " 18  bs_snatch            81616 non-null   float64\n",
      " 19  bs_deadlift          94546 non-null   float64\n",
      " 20  bs_fightgonebad      20402 non-null   float64\n",
      " 21  bs_maxpull_ups       33661 non-null   float64\n",
      " 22  bs_fran              43188 non-null   float64\n",
      " 23  bs_grace             34822 non-null   float64\n",
      " 24  bs_helen             24902 non-null   float64\n",
      " 25  bs_filthy50          13051 non-null   float64\n",
      " 26  bs_sprint400m        16227 non-null   float64\n",
      " 27  bs_run5k             31144 non-null   float64\n",
      " 28  w1_reps_total        325319 non-null  float64\n",
      " 29  w2_reps_total        302688 non-null  float64\n",
      " 30  w2_reps_t2b          302688 non-null  float64\n",
      " 31  w2_reps_du           302688 non-null  float64\n",
      " 32  w2_reps_sqcl         302688 non-null  float64\n",
      " 33  w2_rounds_completed  302688 non-null  float64\n",
      " 34  w2_tiebreak          294956 non-null  float64\n",
      " 35  w3_reps_total        292254 non-null  float64\n",
      " 36  w3_hspu_status       292254 non-null  float64\n",
      " 37  w3_tiebreak          289491 non-null  float64\n",
      " 38  w4_reps_total        280313 non-null  float64\n",
      " 39  w4_reps_bmu          280313 non-null  float64\n",
      " 40  w4_bmu_status        280313 non-null  float64\n",
      " 41  w4_tiebreak          262985 non-null  float64\n",
      " 42  w5_reps_total        254423 non-null  float64\n",
      "dtypes: float64(34), int64(8), object(1)\n",
      "memory usage: 111.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "medium-computer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe without benchmarks or height & weight\n",
    "scores_cols = ['competitorid', 'gender', 'age', 'overallrank', 'is_scaled', \\\n",
    "               'scaled_1', 'scaled_2', 'scaled_3', 'scaled_4', 'scaled_5', \\\n",
    "               'time_2','time_3','time_4','time_5', \\\n",
    "               'w1_reps_total', 'w2_reps_total', 'w2_reps_t2b', 'w2_reps_du', \\\n",
    "               'w2_reps_sqcl', 'w2_rounds_completed', 'w2_tiebreak', 'w3_reps_total', \\\n",
    "               'w3_hspu_status', 'w3_tiebreak', 'w4_reps_total', 'w4_reps_bmu', \\\n",
    "               'w4_bmu_status', 'w4_tiebreak', 'w5_reps_total']\n",
    "df_scores = df[scores_cols]\n",
    "# dataframe with height & weight\n",
    "hw_cols = ['height', 'weight', 'overallrank']\n",
    "df_hw = df[hw_cols]\n",
    "# dataframe with with benchmarks\n",
    "bs_cols = ['overallrank', 'bs_backsquat', 'bs_cleanandjerk', 'bs_snatch', 'bs_deadlift', \\\n",
    "           'bs_fightgonebad', 'bs_maxpull_ups', 'bs_fran', 'bs_grace', 'bs_helen', \\\n",
    "           'bs_filthy50', 'bs_sprint400m', 'bs_run5k']\n",
    "df_bs = df[bs_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "silent-central",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recreational-channel",
   "metadata": {},
   "source": [
    "#### Scores Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "appropriate-captain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 219491 entries, 0 to 338398\n",
      "Data columns (total 29 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   competitorid         219491 non-null  int64  \n",
      " 1   gender               219491 non-null  int64  \n",
      " 2   age                  219491 non-null  float64\n",
      " 3   overallrank          219491 non-null  int64  \n",
      " 4   is_scaled            219491 non-null  int64  \n",
      " 5   scaled_1             219491 non-null  int64  \n",
      " 6   scaled_2             219491 non-null  int64  \n",
      " 7   scaled_3             219491 non-null  int64  \n",
      " 8   scaled_4             219491 non-null  int64  \n",
      " 9   scaled_5             219491 non-null  int64  \n",
      " 10  time_2               219436 non-null  float64\n",
      " 11  time_3               219489 non-null  float64\n",
      " 12  time_4               219464 non-null  float64\n",
      " 13  time_5               219491 non-null  float64\n",
      " 14  w1_reps_total        219491 non-null  float64\n",
      " 15  w2_reps_total        219491 non-null  float64\n",
      " 16  w2_reps_t2b          219491 non-null  float64\n",
      " 17  w2_reps_du           219491 non-null  float64\n",
      " 18  w2_reps_sqcl         219491 non-null  float64\n",
      " 19  w2_rounds_completed  219491 non-null  float64\n",
      " 20  w2_tiebreak          219491 non-null  float64\n",
      " 21  w3_reps_total        219491 non-null  float64\n",
      " 22  w3_hspu_status       219491 non-null  float64\n",
      " 23  w3_tiebreak          219491 non-null  float64\n",
      " 24  w4_reps_total        219491 non-null  float64\n",
      " 25  w4_reps_bmu          219491 non-null  float64\n",
      " 26  w4_bmu_status        219491 non-null  float64\n",
      " 27  w4_tiebreak          219491 non-null  float64\n",
      " 28  w5_reps_total        219491 non-null  float64\n",
      "dtypes: float64(20), int64(9)\n",
      "memory usage: 50.2 MB\n"
     ]
    }
   ],
   "source": [
    "df_scores.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "spatial-throat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(219407, 29)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "academic-hammer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with missing age values\n",
    "df_scores = df_scores[df_scores['age'].notna()]\n",
    "# keep just rows with all 5 workouts participated\n",
    "df_scores = df_scores[df_scores['w1_reps_total'].notna()]\n",
    "df_scores = df_scores[df_scores['w2_reps_total'].notna()]\n",
    "df_scores = df_scores[df_scores['w3_reps_total'].notna()]\n",
    "df_scores = df_scores[df_scores['w4_reps_total'].notna()]\n",
    "df_scores = df_scores[df_scores['w5_reps_total'].notna()]\n",
    "# drop rows with missing time values\n",
    "df_scores = df_scores[df_scores['time_2'].notna()]\n",
    "df_scores = df_scores[df_scores['time_3'].notna()]\n",
    "df_scores = df_scores[df_scores['time_4'].notna()]\n",
    "df_scores = df_scores[df_scores['time_5'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "unlike-future",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set missing tiebreak values to zero\n",
    "df_scores['w2_tiebreak'].replace(np.NaN,0,inplace=True)\n",
    "df_scores['w3_tiebreak'].replace(np.NaN,0,inplace=True)\n",
    "df_scores['w4_tiebreak'].replace(np.NaN,0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "central-premiere",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace categorical values with integer 1/0\n",
    "df_scores['gender'].replace(['M','F'],[1,0],inplace=True)\n",
    "df_scores['w3_hspu_status'].replace([1.0,0.0],[1,0],inplace=True)\n",
    "df_scores['w4_bmu_status'].replace([1.0,0.0],[1,0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dimensional-technical",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(219407, 29)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scores.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "young-operations",
   "metadata": {},
   "source": [
    "#### Heights&Weights Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "seven-moses",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(173135, 3)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "motivated-passage",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hw = df_hw.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "spare-majority",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(173135, 3)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seventh-stereo",
   "metadata": {},
   "source": [
    "#### Benchmark Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "young-laugh",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2067, 13)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cooked-architecture",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bs = df_bs.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "reliable-title",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2067, 13)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sufficient-morocco",
   "metadata": {},
   "source": [
    "### Create Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "executed-chuck",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_sc, test_set_sc = train_test_split(df_scores, test_size=0.3, random_state=42)\n",
    "train_set_hw, test_set_hw = train_test_split(df_hw, test_size=0.3, random_state=42)\n",
    "train_set_bs, test_set_bs = train_test_split(df_bs, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "italic-parker",
   "metadata": {},
   "source": [
    "### Looking at correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "amateur-thousand",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "overallrank            1.000000\n",
       "scaled_2               0.573746\n",
       "scaled_4               0.544067\n",
       "scaled_5               0.537383\n",
       "scaled_3               0.526104\n",
       "w3_tiebreak            0.521726\n",
       "competitorid           0.422018\n",
       "scaled_1               0.420738\n",
       "is_scaled              0.402913\n",
       "w4_tiebreak            0.365851\n",
       "gender                 0.179956\n",
       "time_3                 0.044834\n",
       "age                    0.041459\n",
       "time_4                 0.024954\n",
       "time_2                 0.019516\n",
       "time_5                 0.012619\n",
       "w2_reps_sqcl          -0.026451\n",
       "w2_rounds_completed   -0.028457\n",
       "w2_reps_t2b           -0.030240\n",
       "w2_reps_total         -0.030924\n",
       "w2_reps_du            -0.031688\n",
       "w2_tiebreak           -0.045819\n",
       "w4_bmu_status         -0.171023\n",
       "w5_reps_total         -0.178179\n",
       "w4_reps_total         -0.246123\n",
       "w4_reps_bmu           -0.246409\n",
       "w3_hspu_status        -0.406268\n",
       "w3_reps_total         -0.499977\n",
       "w1_reps_total         -0.524824\n",
       "Name: overallrank, dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix_sc = train_set_sc.corr()\n",
    "corr_matrix_sc['overallrank'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "personal-malta",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "overallrank    1.000000\n",
       "weight         0.206267\n",
       "height         0.167184\n",
       "Name: overallrank, dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix_hw = train_set_hw.corr()\n",
    "corr_matrix_hw['overallrank'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dangerous-catalyst",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "overallrank        1.000000\n",
       "bs_fran            0.482549\n",
       "bs_helen           0.387525\n",
       "bs_filthy50        0.366112\n",
       "bs_grace           0.351305\n",
       "bs_run5k           0.244740\n",
       "bs_sprint400m      0.195070\n",
       "bs_deadlift       -0.070626\n",
       "bs_backsquat      -0.120233\n",
       "bs_cleanandjerk   -0.208112\n",
       "bs_snatch         -0.252759\n",
       "bs_maxpull_ups    -0.350511\n",
       "bs_fightgonebad   -0.391688\n",
       "Name: overallrank, dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix_bs = train_set_bs.corr()\n",
    "corr_matrix_bs['overallrank'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viral-auckland",
   "metadata": {},
   "source": [
    "### Define Target and Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "comprehensive-means",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sc = df_scores['overallrank']\n",
    "X_sc = df_scores.drop(axis=1,columns='overallrank')\n",
    "\n",
    "y_hw = df_hw['overallrank']\n",
    "X_hw = df_hw.drop(axis=1,columns='overallrank')\n",
    "\n",
    "y_bs = df_bs['overallrank']\n",
    "X_bs = df_bs.drop(axis=1,columns='overallrank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "increased-command",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sc, X_test_sc, y_train_sc, y_test_sc = train_test_split(X_sc, y_sc, random_state=42)\n",
    "X_train_hw, X_test_hw, y_train_hw, y_test_hw = train_test_split(X_hw, y_hw, random_state=42)\n",
    "X_train_bs, X_test_bs, y_train_bs, y_test_bs = train_test_split(X_bs, y_bs, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "judicial-frame",
   "metadata": {},
   "source": [
    "### Linear Regression Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "interim-scotland",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "greek-enforcement",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg.fit(X_train_sc, y_train_sc)\n",
    "y_pred_sc = lin_reg.predict(X_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "signed-clinic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9 % of error in overall ranking. Absolute rank error: 3502\n"
     ]
    }
   ],
   "source": [
    "lin_mse = mean_squared_error(y_test_sc,y_pred_sc)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "print(round((int(lin_rmse)/185550)*100,1),\n",
    "      '% of error in overall ranking. Absolute rank error:', int(lin_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "pursuant-board",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg.fit(X_train_hw, y_train_hw)\n",
    "y_pred_hw = lin_reg.predict(X_test_hw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "speaking-dubai",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.65481 % of error in overall ranking. Absolute rank error: 49458\n"
     ]
    }
   ],
   "source": [
    "lin_mse = mean_squared_error(y_test_hw,y_pred_hw)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "print(round((int(lin_rmse)/185550)*100,1),\n",
    "      '% of error in overall ranking. Absolute rank error:', int(lin_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "athletic-sport",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg.fit(X_train_bs, y_train_bs)\n",
    "y_pred_bs = lin_reg.predict(X_test_bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "greenhouse-offense",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.3 % of error in overall ranking. Absolute rank error: 34028\n"
     ]
    }
   ],
   "source": [
    "lin_mse = mean_squared_error(y_test_bs,y_pred_bs)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "print(round((int(lin_rmse)/185550)*100,1),\n",
    "      '% of error in overall ranking. Absolute rank error:', int(lin_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "double-checkout",
   "metadata": {},
   "source": [
    "### Decision Tree Regression Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "reasonable-greeting",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_reg = DecisionTreeRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "referenced-catalyst",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_cols = ['competitorid','gender','age','time_2','time_3', \\\n",
    "              'time_4', 'time_5', 'w1_reps_total', 'w2_reps_total', 'w2_reps_t2b', \\\n",
    "              'w2_reps_du', 'w2_reps_sqcl', 'w2_rounds_completed', 'w2_tiebreak', \\\n",
    "              'w3_reps_total', 'w3_tiebreak', 'w4_reps_total', 'w4_reps_bmu', \\\n",
    "              'w4_tiebreak', 'w5_reps_total'\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "technological-minister",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled_sc = scaler.fit_transform(X_train_sc[scale_cols])\n",
    "X_test_scaled_sc = scaler.transform(X_test_sc[scale_cols])\n",
    "\n",
    "X_train_scaled_hw = scaler.fit_transform(X_train_hw)\n",
    "X_test_scaled_hw = scaler.transform(X_test_hw)\n",
    "\n",
    "X_train_scaled_bs = scaler.fit_transform(X_train_bs)\n",
    "X_test_scaled_bs = scaler.transform(X_test_bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "passive-system",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating scaled and dummy columns \n",
    "X_train_preprocessed_sc = np.concatenate([X_train_scaled_sc, X_train_sc.drop(scale_cols, axis=1)], axis=1)\n",
    "X_test_preprocessed_sc = np.concatenate([X_test_scaled_sc, X_test_sc.drop(scale_cols, axis=1)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "amino-relative",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_reg.fit(X_train_preprocessed_sc, y_train_sc)\n",
    "y_pred_sc = tree_reg.predict(X_test_preprocessed_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "valuable-sally",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9 % of error in overall ranking. Absolute rank error: 3545\n"
     ]
    }
   ],
   "source": [
    "lin_mse = mean_squared_error(y_test_sc,y_pred_sc)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "print(round((int(lin_rmse)/185550)*100,1),\n",
    "      '% of error in overall ranking. Absolute rank error:', int(lin_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "thrown-merchant",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_reg.fit(X_train_scaled_hw, y_train_hw)\n",
    "y_pred_hw = tree_reg.predict(X_test_scaled_hw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "respiratory-verse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.7 % of error in overall ranking. Absolute rank error: 49566\n"
     ]
    }
   ],
   "source": [
    "lin_mse = mean_squared_error(y_test_hw,y_pred_hw)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "print(round((int(lin_rmse)/185550)*100,1),\n",
    "      '% of error in overall ranking. Absolute rank error:', int(lin_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "dedicated-professional",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_reg.fit(X_train_scaled_bs, y_train_bs)\n",
    "y_pred_bs = tree_reg.predict(X_test_scaled_bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "cleared-ozone",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.9 % of error in overall ranking. Absolute rank error: 49892\n"
     ]
    }
   ],
   "source": [
    "lin_mse = mean_squared_error(y_test_bs,y_pred_bs)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "print(round((int(lin_rmse)/185550)*100,1),\n",
    "      '% of error in overall ranking. Absolute rank error:', int(lin_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "concerned-board",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(tree_reg, X_train_scaled_hw, y_train_hw, cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "renewable-dakota",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.0298\n"
     ]
    }
   ],
   "source": [
    "print('Score:', round(scores.mean(), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "manual-auditor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.axhline(y=scores.mean(), color='y', linestyle='-')\n",
    "sns.barplot(x=[1,2,3,4, 5],y=scores).set_title('Scores of the K-Folds Models - unscaled data');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automated-mentor",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "fluid-sarah",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ccp_alpha', 'criterion', 'max_depth', 'max_features', 'max_leaf_nodes', 'min_impurity_decrease', 'min_impurity_split', 'min_samples_leaf', 'min_samples_split', 'min_weight_fraction_leaf', 'random_state', 'splitter'])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_reg.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "virgin-tutorial",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining parameter grid (as dictionary)\n",
    "param_grid = {\"max_depth\" : [10,15,20],\n",
    "              \"max_features\" : [1,2,3],\n",
    "              \"max_leaf_nodes\" : [80,100,120],\n",
    "              \"min_impurity_decrease\" : [0.05],\n",
    "              #\"min_impurity_split\" : [],\n",
    "              #\"min_samples_leaf\" : [],\n",
    "              #\"min_samples_split\" : [],\n",
    "              #\"min_weight_fraction_leaf\" : [],\n",
    "             }\n",
    "\n",
    "# Instantiate gridsearch and define the metric to optimize \n",
    "gs = GridSearchCV(tree_reg, param_grid, cv=5, verbose=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "young-circumstances",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juliusjenek/Documents/neuefische/project-crossfit-data/.venv/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.06438409 0.06593296 0.06628377 0.06954836 0.06932804 0.06923208\n",
      "        nan        nan        nan 0.0649146  0.06650196 0.06343183\n",
      " 0.07035996 0.07068484 0.07066946        nan        nan        nan\n",
      " 0.06281694 0.06841554 0.06871124 0.07035996 0.07065591 0.07063349\n",
      "        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeRegressor(), n_jobs=-1,\n",
       "             param_grid={'max_depth': [10, 15, 20], 'max_features': [1, 2, 3],\n",
       "                         'max_leaf_nodes': [80, 100, 120],\n",
       "                         'min_impurity_decrease': [0.05]},\n",
       "             verbose=5)"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(X_train_scaled_hw, y_train_hw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "known-morning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Results from Grid Search \n",
      "\n",
      " The best estimator across ALL searched params:\n",
      " DecisionTreeRegressor(max_depth=15, max_features=2, max_leaf_nodes=100,\n",
      "                      min_impurity_decrease=0.05)\n",
      "\n",
      " The best score across ALL searched params:\n",
      " 0.07068483975775461\n",
      "\n",
      " The best parameters across ALL searched params:\n",
      " {'max_depth': 15, 'max_features': 2, 'max_leaf_nodes': 100, 'min_impurity_decrease': 0.05}\n"
     ]
    }
   ],
   "source": [
    "print(\" Results from Grid Search \" )\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\",gs.best_estimator_)\n",
    "print(\"\\n The best score across ALL searched params:\\n\",gs.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",gs.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
